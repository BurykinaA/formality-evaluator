# Formal vs. Informal Text Classification

This project focuses on classifying text as formal or informal using various machine learning approaches. It includes data generation, dataset preparation, and evaluation tools.

## Project Structure

### Data Generation and Preparation

- **generate_gpt_data.py**: Generates synthetic examples of formal and informal text using OpenAI's GPT-3.5 API.
- **gyafc_generate.py**: Processes the GYAFC (Grammarly's Yahoo Answers Formality Corpus) dataset.
- **prepare_datasets.py**: Prepares datasets from Reddit (informal) and Enron emails (formal) for training and evaluation.

### Evaluation

The `evaluate` directory contains tools for evaluating models:

- **run_finetune.py**: Fine-tunes transformer models for formal/informal classification.
- **run_similarity.py**: Evaluates models using a similarity-based approach.
- **scripts/**: Contains shell scripts for running evaluations:
  - **ft.sh**: Script for running fine-tuning evaluations.
  - **sim.sh**: Script for running similarity-based evaluations.
- **utils/**: Utility functions for the evaluation process:
  - **data.py**: Data preparation utilities.
  - **get_embeddings.py**: Functions for calculating text embeddings.
  - **model.py**: Model definitions for classification.
  - **test_utils.py**: Evaluation metrics and testing utilities.

### Datasets

The `data` directory contains the processed datasets:
- **gpt_generated.txt**: Synthetic formal/informal text pairs generated by GPT.
- **gyafc.txt**: Processed GYAFC dataset.
- **reddit_enron_combined.txt**: Combined dataset from Reddit (informal) and Enron emails (formal).

## Usage

### Data Generation

1. Set your OpenAI API key in the environment:
   ```
   export OPENAI_API_KEY=your_api_key
   ```

2. Generate synthetic data:
   ```
   python generate_gpt_data.py
   ```

3. Process GYAFC data:
   ```
   python gyafc_generate.py
   ```

4. Prepare Reddit and Enron datasets:
   ```
   python prepare_datasets.py
   ```

### Evaluation

1. Fine-tune a model:
   ```
   bash evaluate/scripts/ft.sh
   ```

2. Evaluate using similarity approach:
   ```
   bash evaluate/scripts/sim.sh
   ```

## Models

The project supports various transformer models:
- distilbert-base-uncased
- dunzhang/stella_en_400M_v5
- Alibaba-NLP/gte-large-en-v1.5
- HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1

## Evaluation Methods

1. **Fine-tuning**: Traditional supervised learning approach where models are fine-tuned on labeled data.
2. **Similarity-based**: Uses text embeddings to measure similarity between queries and responses to determine formality.


